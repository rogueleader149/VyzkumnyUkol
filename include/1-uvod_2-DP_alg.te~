\section{DP algoritmus}

\begin{tvrzeni}[Princip optimality]
	Buď $\pi^* = (\adob{\mu_0^*}{\mu_{N-1}^*})$ optimální strategie pro zá\-klad\-ní problém a předpokládejme, že v $i$-tém kroku nastane stav $x_i$. Uvažme podproblém s počátečním stavem $x_i$. Potom podstrategie $(\adob{\mu_i^*}{\mu_{N-1}^*})$ je optimální pro tento podproblém.
\end{tvrzeni}

\begin{proof}
	Kdyby tato podstrategie nebyla optimální, existovala by lepší podstrategie $\tilde{\pi}^i$. Potom by ale nebyla optimální ani původní, protože bychom při teoretickém dosažení $x_i$ mohli \uv{přepnout} na $\tilde{\pi}^i$, která je lepší než v tu chvíli vykonávaná $(\adob{\mu_i^*}{\mu_{N-1}^*})$. To jest spor s předpokladem optimality $\pi^*$.
\end{proof}

\begin{tvrzeni}[DP algoritmus]
\label{tvr:DP_alg}
	Pro každé $x_0 \in S_0$ je dána optimální ztráta $J^*(x_0) = J_0(x_0)$ z posledního kroku následujícího rekurzivního algoritmu:
	\begin{align}
		J_N(x_N) &= g_N(x_N) ,\nonumber\\
		J_k(x_k) &= \min\limits_{u_k \in U_k(x_k)} \; \E\limits_{w_k} \Bigl\{ g_k(x_k, u_k, w_k) + J_{k+1}\bigl(f_k(x_k, u_k, w_k)\bigr) \Bigr\} , \quad k \in \{\adob{0}{N \! - \! 1}\} . \label{eqn:DP_alg}
	\end{align}
	za předpokladu že všechna minima existují.
	
	Navíc, pokud pro každé $x_k$ a $k$ sestrojíme funkce $\mu_k^*$ tak, že pro dané $x_k$ minimalizuje $u_k^* = \mu_k^*(x_k)$ pravou stranu rovnice \eqref{eqn:DP_alg}, je strategie $\pi^* = (\adob{\mu_0^*}{\mu_{N-1}^*})$ optimální.
\end{tvrzeni}

\begin{proof}\footnote{Jedná se pouze o náznak důkazu, pro rigorózní důkaz viz \cite{bib:ber_shr}. Komplikace v důkazu nenastanou, pokud jsou všechny střední očekávané ztráty dobře definované a konečné pro každou strategii $\pi$ a poruchy $w_k$ nabývají nejvýše spočetně mnoha hodnot, rozebráno v \cite{bib:bert}.}
	Pro každou strategii $\pi = (\adob{\mu_0}{\mu_{N-1}})$ a každé $k \in \{\adob{0}{N-1}\}$ označme $\pi^k = (\adob{\mu_k}{\mu_{N-1}})$. Dále buď $J_k^*(x_k)$ optimální ztráta $(N-k)$-stupňového problému začínajícího v $x_k$ v čase $k$, tedy
	\begin{align*}
		J_k^*(x_k) &= \min\limits_{\pi^k} \; \E\limits_{w_i} \Biggl\{ g_N(x_N) + \sum\limits_{j=k}^{N-1} g_j\big(x_j, \mu_j(x_j), w_j\big) \Biggr\} , \\
		J_N^*(x_N) &= g_N(x_N) .
	\end{align*}
	Ukážeme indukcí že se funkce $J_k^*$ rovnají funkcím $J_k$ generovaným DP algoritmem. Tím bude tvrzení dokázáno, protože  $J^* = J_0^* = J_0$.
	
	Z definice máme $J_N^* = J_N = g_N$. Nyní předpokádejme (indukční předpoklad), že pro nějaké $k \in \{\adob{0}{N-1}\}$ platí pro všechna $x_{k+1}$ rovnost $J_{k+1}^*(x_{k+1}) = J_{k+1}(x_{k+1})$. Potom, protože $\pi^k = (\mu_k, \pi^{k+1})$, máme pro každé $x_k$
	\begin{align*}   % závorky v cajku
		J_k^*(x_k) &= \min\limits_{(\mu_k, \pi^{k+1})} \; \E\limits_{w_i} \Biggl\{ g_k\bigl(x_k, \mu_k(x_k), w_k\bigr) + g_N(x_N) + \sum\limits_{j=k+1}^{N-1} g_j\bigl(x_j, \mu_j(x_j), w_j\bigr) \Biggr\} = \\
		&= \min\limits_{\mu_k} \; \E\limits_{w_k} \left\{ g_k\bigl(x_k, \mu_k(x_k), w_k\bigr) + \min\limits_{\pi^{k+1}} \E\limits_{w_i} \Biggl\{ g_N(x_N) + \sum\limits_{j=k+1}^{N-1} g_j\bigl(x_j, \mu_j(x_j), w_j\bigr) \Biggr\} \right\} = \\
		&= \min\limits_{\mu_k} \; \E\limits_{w_k} \Bigl\{ g_k\bigl(x_k, \mu_k(x_k), w_k\bigr) + J_{k+1}^*\bigl(f_k(x_k, \mu_k(x_k), w_k)\bigr) \Bigr\} = \\
		&= \min\limits_{\mu_k} \; \E\limits_{w_k} \Bigl\{ g_k\bigl(x_k, \mu_k(x_k), w_k\bigr) + J_{k+1}\bigl(f_k(x_k, \mu_k(x_k), w_k)\bigr) \Bigr\} = \\
		&= \min\limits_{u_k \in U_k(x_k)} \; \E\limits_{w_k} \Bigl\{ g_k(x_k, u_k, w_k) + J_{k+1}\bigl(f_k(x_k, u_k, w_k)\bigr) \Bigr\} = \\
		&= J_k(x_k).
	\end{align*}
	Ve druhé rovnosti jsme použili princip optimality (část strategie je optimální pro odpovídající podproblém), ve třetí rovnosti jsme použili definici $J_{k+1}^*$, ve čtvrté indukční předpoklad a v páté pouze nahradili výsledek strategie jejím oborem hodnot.
\end{proof}

\begin{priklad}[Násobení matic]
	Mějme součin matic $M_1 M_2 \ldots M_n$, kde matice $M_k$ má rozměry $n_k \times n_{k+1}$. Všimneme si, že pořadí, ve kterém matice násobíme, může ovlivnit celkový počet operací. Například pro $n_1 = 1$, $n_2 = 10$, $n_3 = 1$ a $n_4 = 10$, výpočet $\bigl((M_1 M_2)M_3\bigr)$ vyžaduje 20 násobení, kdežto $\bigl(M_1 (M_2 M_3)\bigr)$ vyžaduje 200 násobení.
	
	Nalezněme DP algoritmus, který najde pořadí s minimálním počtem operací. Předně musíme definovat \uv{stav} produktu matic -- bude jím uspořádaná $(n+1)$-tice příslušných rozměrů. Počáteční stav $x_0$ tedy bude $(\adob{n_1}{n_{N+1}})$. Zásah $u_k$ budeme reprezentovat indexem prvku z $x_k$ bez krajních členů $n_1$ a $n_{N+1}$, bude vyjadřovat vynásobení matic s pří\-sluš\-ným společným rozměrem. Tento prvek pak už nebudeme moci vybrat, proto rovnice vývoje systému bude $x_{k+1} = x_k \ominus \{u_k\}$ (vyjadřuje odebrání prvku s indexem $u_k$). Zásahů bude dohromady $N-1$, přičemž koncový stav bude $x_{N-1} = (n_1, n_{N+1})$ s nulovou koncovou ztrátou. Ztráta v $k$-tém kroku bude $g_k(x_k, u_k) = n_\alpha n_{u_k} n_\beta$, kde
	\begin{align*}
		\alpha &= \max\bigl\{i \in \{\adob{1}{N+1}\} \bigm| i < u_k, i \in x_k\bigr\} , \\
		\beta &= \min\bigl\{i \in \{\adob{1}{N+1}\} \bigm| i > u_k, i \in x_k\bigr\} .
	\end{align*}
	DP algoritmus pak dostává tvar
	\begin{align*}
		J_{N-1}(x_{N-1}) &= 0 , \\
		J_k(x_k) &= \min\limits_{u_k \in x_k \ominus \{ 1, N+1 \}} \bigl[ n_\alpha n_{u_k} n_\beta + J_{k+1}(x_k \ominus \{u_k\}) \bigr] , \quad k = \adob{0}{N-2} .
	\end{align*}
	Například pro hodnoty $(2, 10, 5, 1)$ potřebujeme 70 operací, optimální pořadí je $M_1(M_2 M_3)$.
\end{priklad}

\subsection{Rozšíření stavu a další formulace}
\label{subsec:augment}
	
	Přestože byl základní problém formulován dosti obecně, někdy se může stát, že základní předpoklady nebudou pro daný problém splněny. Často však lze takový problém přeformulovat do rámce základního problému, ale typicky to s sebou přináší zvětšení stavových prostorů. Obecný návod totiž zní: do $k$-tého stavu zahrneme veškerou nám tou dobou známou informaci o předchozích stavech a zásazích potřebnou pro další rozhodování. Bohužel, rozšíření stavů může vést k fatálnímu nárustu výpočetní náročnosti. Uvedeme si zde několik případů včetně postupu jak je přeformulovat.
	
	\subsubsection*{Časová zpoždění}
		
		Může se stát, že stav $x_{k+1}$ nebo ztrátová funkce nezávisí pouze na předchozím stavu a zásahu, ale na několika předchozích. V tomto případě obohatíme $k$-tý stav o potřebný počet předchozích stavů a zásahů -- vytvoříme uspořádanou $l_k$-tici.  Pro každé $k$ tak nahradíme $S_k$ odpovídajícím prostorem a formulace pro takové $l_k$-tice už vyhovuje rámci základního problému.
		
		Extrémní případ nastane např. pro neaditivní ztrátovou funkci $$ g_N(\adob{x_0}{x_N}, \adob{u_0}{u_{N-1}}, \adob{w_0}{w_{N-1}}) . $$ Potom musíme brát celou historii jako rozšířený stav.
		
	\subsubsection*{Závislé náhodné poruchy}
		
		Jako příklad závislé náhodné poruchy uvedeme vývoj $w_k$ podle rovnice tvaru $w_k = W_k(w_{k-1}, \newline \xi_k)$, kde $W_k$ jsou dané funkce a $(\xi_k)_{k=0}^{N-1}$ je posloupnost náhodných vektorů s daným rozdělením. Pak přidáme stavovou proměnnou $y_k = w_{k-1}$ a dostáváme novou rovnici vývoje systému
		$$ X_{k+1} = \left( \begin{array}{c} x_{k+1}\\ y_{k+1}\\ \end{array} \right) = \left( \begin{array}{c} f_k\bigl(x_k, u_k, W_k(y_k, \xi_k)\bigr)\\ W_k(y_k, \xi_k)\\ \end{array} \right) = F_k(X_k, u_k, \xi_k) , $$
		která už zapadá do rámce základního problému.
	
	\subsubsection*{Zjednodušení stavového prostoru}
		
		V případě, že některá komponenta systému není ovlivňována naším zásahem, ale jen nepřímo, může být vypuštěna, jak bude ukázáno.
		
		Mějme dvousložkový systém $(x_k, y_k)$ vyvíjející se podle rovnic $x_{k+1} = f_k(x_k, y_k, u_k, w_k)$ s daným rozdělením $P_k(w_k \mid x_k, y_k, u_k)$, a $y_{k+1}$ je dáno jen rozdělením $P_{k+1}(\cdot \mid x_{k+1})$, tudíž není přímo ovlivněno naším zásahem, jen nepřímo skrz $x_{k+1}$. Mohlo by se zdát, že $y_k$ lze považovat jen za poruchu, je zde však zásadní rozdíl: $w_k$ se objeví po zásahu $u_k$, kdežto $y_k$ známe už před zásahem $u_k$, tudíž může náš výběr ovlivnit.
		
		Nyní ukážeme DP algoritmus, který operuje pouze nad prostorem kontrolovatelné stavové komponenty, přičemž závislost na nekontrolovatelné komponentě bude vystředována. Buď $J_k(x_k, y_k)$ optimální ztráta v čase $k$ a stavu $(x_k, y_k)$. Definujme
		$$ \hat{J}_k(x_k) = \E\limits_{y_k} \bigl\{ J_k(x_k, y_k) \bigm| x_k \bigr\} , $$
		což je hledaná optimální střední ztráta pro dané $x_k$ v čase $k$.
		
		Nyní odvodíme variantu DP algoritmu, který takové $\hat{J}_k(x_k)$ najde.
		\begin{align}   % závorky v cajku
			\hat{J}_k(x_k) = &\E\limits_{y_k} \bigl\{ J_k(x_k, y_k) \bigm| x_k \bigr\} = \nonumber\\
			= &\E\limits_{y_k} \biggl\{ \min\limits_{u_k \in U_k(x_k, y_k)} \; \E\limits_{w_k, x_{k+1}, y_{k+1}} \Bigl\{ g_k(x_k, y_k, u_k, w_k) + \nonumber\\
			&+ \; J_{k+1}(x_{k+1}, y_{k+1}) \Bigm| x_k, y_k, u_k \Bigr\} \biggm| x_k \biggr\} = \nonumber\\
			= &\E\limits_{y_k} \biggl\{ \min\limits_{u_k \in U_k(x_k, y_k)} \; \E\limits_{w_k, x_{k+1}} \Bigl\{ g_k(x_k, y_k, u_k, w_k) + \nonumber\\
			&+ \E\limits_{y_{k+1}} \bigl\{ J_{k+1}(x_{k+1}, y_{k+1}) \bigm| x_{k+1} \bigr\} \Bigm| x_k, y_k, u_k \Bigr\} \biggm| x_k \biggr\} = \nonumber\\
			= &\E\limits_{y_k} \biggl\{ \min\limits_{u_k \in U_k(x_k, y_k)} \; \E\limits_{w_k} \Bigl\{ g_k(x_k, y_k, u_k, w_k) + \nonumber\\
			&+ \hat{J}_{k+1} \bigl( f_k(x_k, y_k, u_k, w_k) \bigr) \Bigr\} \biggm| x_k \biggr\} . \label{eqn:omez}
		\end{align}
		První krok je rozepsaný DP algoritmus, poslední jen vyžívá definici $\hat J_{k+1}$. Zajímavý je tak pouze druhý krok. Pokud si vypíšeme hustoty pravděpodobnosti potřebné pro středování, dostaneme u $g_k$ pouze marginální hustotu ($y_{k+1}$ se v $g_k$ nevyskytuje), u $J_{k+1}$ bude situace komplikovanější. Zde se vyskytnou postupně dvě hustoty $p(y_{k+1} \mid x_{k+1})$ a $p(w_k, x_{k+1} \mid x_k, y_k, u_k)$ namísto původní $p(w_k, x_{k+1}, y_{k+1} \mid x_k, y_k, u_k)$. K dokončení budeme potřebovat jednoduché pozorování.
		
		\begin{pozorovani} \label{poz:podm_nez}
			Mějme dvě podmíněně nezávislé náhodné veličiny s hustotami
			$$ p(x, y \mid z) = p(x \mid z) \; p(y \mid z). $$
			Potom $p(x \mid y, z) = p(x \mid z)$.
		\end{pozorovani}
		
		\begin{proof}
			$$ p(x \mid y, z) = p(x, y \mid z) \; \frac{p(z)}{p(y,z)} = p(x \mid z) . $$
			V prvním kroku jsme přepsali dle definice a rozšířili $p(z)$, ve druhém použili předpoklad a vykrátili.
		\end{proof}
		
		V našem případě použijeme podmíněnou nezávislost $y_{k+1}$ podmíněno $x_{k+1}$ -- jak stojí v zadání problému, $y_{k+1}$ závisí explicitně {\em pouze} na $x_{k+1}$, s ostatními veličinami je proto podmíněně nezávislé. Odtud již snadno s použitím pozorování \ref{poz:podm_nez}
		\begin{align*}
			p(y_{k+1} \mid x_{k+1}) \; p(w_k, x_{k+1} \mid x_k, y_k, u_k) &= p(y_{k+1} \mid x_{k+1}, x_k, y_k, u_k, w_k) \; p(w_k, x_{k+1} \mid x_k, y_k, u_k) = \\
			&= p(w_k, x_{k+1}, y_{k+1} \mid x_k, y_k, u_k) .
		\end{align*}
		
		Výhodou této modifikace DP algoritmu je zmenšení prostoru, přes který je počítaný, což může v některých případech vést k realizovatelnosti jinak nereálného výpočtu. Navíc, i přes zjednodušení, obdržíme strategii jako funkci plného stavu $(x_k, y_k)$.
		
		Příkladem systému s nekontrolovatelnými komponentami je odbavování front, kde musíme při rozhodování zohlednit i náhodný jev -- nově příchozí $y_k$. Jejich počet naším zásahem přímo neovlivníme, pouze nepřímo přes počet čekajících $x_k$ (člověk vidíce dlouhou frontu pravděpodobně zklamaně odchází). Stavový prostor tedy obsahuje dvě proměnné, přesto stačí DP algoritmus provést pouze nad prostorem čekajících podle \eqref{eqn:omez}.
	
\subsection{DP bez stochastického popisu náhodných poruch}
	
	Další modifikaci DP musíme vybudovat pro případ, že není dané rozdělení náhodných poruch. Doteď jsme uvažovali za optimální strategii tu, která dávala nejnižší očekávanou ztrátu. Nyní, když rozdělení neznáme, se budeme snažit minimalizovat ztrátu v nejnepříznivějším případě. Takový přístup se nazývá \uv{minimax}, protože minimalizuje maximální (tedy nejhorší) možnou hodnotu.
	
	V nejjednodušší formě máme pouze množinu strategií $\Pi$, obor hodnot náhodných veličin $W$ a $J : \Pi \times W \rightarrow \R^*$ je daná ztrátová funkce. Cílem je najít $\pi^*$ takové, že minimalizuje
	$$ \min\limits_{\pi \in \Pi} \; \max\limits_{w \in W} \; J(\pi, w) $$
	za předpokladu, že všechna minima a maxima existují.
	
	V DP algoritmu pak pouze nahradíme střední hodnotu maximem přes příslušnou množinu, minimum zůstane na svém místě. V důkazu se využívá analogický argument o optimalitě podproblému, pro detaily o prohození $\min \leftrightarrow \max$ viz \cite[sekce 1.6]{bib:bert1}.
	
	\begin{priklad}[Odebírání zápalek]
		Příkladem na minimax je známá hra odebírání zápalek: dva hráči $A$ a $B$ střídavě odebírají z hromádky $n$ zápalek buď jednu, dvě, nebo tři zápalky s cílem odebrat poslední. Úkolem je optimalizovat strategii začínajícího hráče (BÚNO $A$). Roli stavu hraje počet sirek před tahem $A$, roli zásahu počet odebraných sirek hráčem $A$, roli poruchy počet odebraných hráčem $B$, systém se vyvíjí podle $x_{k+1} = x_k - u_k - w_k$ a ztrátová funkce je rekurzivně definovaná z počátečních podmínek
		\begin{itemize}
			\item $J(0) = 1 ,$
			\item $J(1, 2, 3) = 0$
		\end{itemize}
		ve smyslu penále, a rekurze
		$$ J(k) = \min\limits_{u\in\{1, 2, 3\}}\max\limits_{w\in\{1, 2, 3\}}\bigl[J(k - u - w)\bigr]. $$
	\end{priklad}
	
\subsection{DP v deterministických modelech} \label{subsec:deter}
	
	Další možností modifikace je úplné vynechání stochastických jevů (neboli náhrada všech rozdělení za Diracova). Zásadní rozdíl oproti ryze stochastickým systémům spočívá v tom, že znalost stavu už nehraje žádnou roli -- vývoj systému je jednoznačně dán počátečním stavem $x_0$ a zásahy $\adob{u_0}{u_{N-1}}$. Optimalizace se tak provádí pouze přes zásahy $(\adob{u_0}{u_{N-1}})$, open- a closed-loop strategie splývají (viz sekci \ref{sec:info}).
