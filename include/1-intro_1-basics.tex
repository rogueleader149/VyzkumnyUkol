	
	1959: Feynman's visionary talk, \cite{feynman}; pros: extreme paralelism, cons: reliability.
	
	The ground-breaking work was carried out by Adleman, \cite{adleman94}, who showed that DNA computation is practically feasible. In his experiment, Adleman used special DNA sequences for solving Hamiltonian Path Problem, one of the most typical $\NPC$ problems.
	
	... Extreme parallelism! But also possibility of errors.

\section*{Work overview}
	
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	
	Chapter 1: Intro.\\
	Chapter 2: First of all we will describe models which exploit specific DNA structure.\\
	Chapter 3: Abstract Tile Assembly Model, temperature, 2D vs. 3D.\\
	Positive integers $\N$. \nomenclature{$\N$}{Positive integers.}
	
	% zkusíme Ramseyovo číslo R(5,5) ? :)
	% -> problém "Je R(n,n) větší než něco?" znamená pro odpověď ANO najít graf t.ž. neobsahuje K_n ani anti-K_n .. což je samo o sobě co-NP (neboli to je \exists \forall stroj .. \Sigma_2 jazyk, horní hranice pak je \Pi_2 jazyk)
	% 
	% NP vs co-NP .. co-NP přece nedává ne?

\section{Basic DNA principles}
	
	DNA (deoxyribonucleic acid) is a large biomolecule carrying genetic information of living organisms. Its most common structure is well-known double-helix which consists of two strands connected by hydrogen bonds. These strands are biopolymers built up by {\em polymerase chain reaction} (PCR) from small units -- nucleotides. Each nucleotide consists of two parts: nitrogenous base and backbone molecules.
	\begin{description}
		\item[Nitrogenous bases.] There are $4$ nucleobases in DNA ($+1$ in RNA): Adenine ({\bf A}), Thymine ({\bf T}), Cytosine ({\bf C}), Guanine ({\bf G}) and Uracil ({\bf U}) in RNA instead of Thymine in DNA. These molecules are responsible for making hydrogen bonds between strands in a manner following Watson-Crick complementarity: only {\bf A} -- {\bf T} and {\bf C} -- {\bf G} pairs can be formed.
		\item[Backbone molecules.] Backbone of DNA strand is made of alternating deoxyriboses and phosphates. Phosphates only hold adjacent deoxyriboses, each deoxyribose moreover holds one nucleobase. Due to deoxyribose carbon numbering, DNA backbone has so-called $5'$ and $3'$ ends, default reading order is $5'\rightarrow 3'$. DNA strands must be antiparallel so that nucleobases can connect.
	\end{description}
	%!% definovat Watson-Crick complementarity

\section{Complexity and languages}
	
	\subsection{Big $O$ and other notations}
		
		Let us briefly remind $O$-, $o$-, $\Omega$-, $\omega$- and $\Theta$-notations for functions on positive integers. We will denote $(\exists n_0 \in \N) (\forall n > n_0)$ shortly by $(\forall^* n)$ which can be read ``for almost all $n$''. Also $(\forall n_0 \in \N) (\exists n > n_0)$ will be denoted by $(\exists^\infty n)$ which can be read ``there exist infinitely many~$n$''.
		\begin{defn}
		\label{def:O}
		Let $f, g: \N \rightarrow \N$.
		\begin{align*}
			O(f) &= \bigl\{\, g \bigm| (\exists C > 0) (\forall^* n) \bigl(g(n) < C f(n)\bigr)\bigr\} \\[5pt]
			\omega^{(1)}(f) &= \bigl\{\, g \bigm| (\forall C > 0) (\exists^\infty n) \bigl(g(n) > C f(n)\bigr)\bigr\} \\[5pt]
			\omega^{(2)}(f) &= \bigl\{\, g \bigm| (\forall C > 0) (\forall^* n) \bigl(g(n) > C f(n)\bigr)\bigr\} \\[5pt]
			\Omega^{(1)}(f) &= \bigl\{\, g \bigm| (\exists C > 0) (\exists^\infty n) \bigl(g(n) > C f(n)\bigr)\bigr\} \\[5pt]
			\Omega^{(2)}(f) &= \bigl\{\, g \bigm| (\exists C > 0) (\forall^* n) \bigl(g(n) > C f(n)\bigr)\bigr\} \\[5pt]
			o(f) &= \bigl\{\, g \bigm| (\forall C > 0) (\forall^* n) \bigl(g(n) < C f(n)\bigr)\bigr\} \\[5pt]
			\Theta(f) &= \bigl\{\, g \bigm| (\exists C_1, C_2 > 0) (\forall^* n) \bigl(C_1 f(n) \leq g(n) \leq C_2 f(n)\bigr)\bigr\} \\[5pt]
			g \sim f &\iff \lim\limits_{n\to\infty} \frac{g(n)}{f(n)} = 1
		\end{align*}
		\end{defn}
		
		\begin{remark}
			Note that there are two distinct definitions for omegas. The class $\Omega^{(1)}$ is equivalent to the orgininal definition introduced by Hardy \cite{hardy1914} which states
			\begin{equation*}
				f \in \Omega(g) \iff \limsup\limits_{n\to\infty}\frac{f(n)}{g(n)} > 0 .
			\end{equation*}
			The second class $\Omega^{(2)}$, was introduced by Knuth for good reasons described in \cite{knuth76}. In similar manner there are two definitions for $\omega$.
		\end{remark}
		\begin{remark}
			Note that there are also some relations: the condition for $\Omega^{(1)}$ is negation of the condition for $o$ so the sets $\Omega^{(1)}(f)$ and $o(f)$ are complementary for given function $f$, similarly for $\omega^{(1)}$ and $O$. For the second variant one can easily check that $f\in\Omega^{(2)}(g)\iff g\in O(f)$ and $f\in\omega^{(2)}(g)\iff g\in o(f)$. There is also an equivalent condition for $\Theta$:
			\begin{equation*}
				g \in \Theta(f) \iff \bigl(g \in O(f) \,\wedge\, f \in O(g)\bigr) \iff \bigl(g \in O(f) \,\wedge\, g \in \Omega^{(2)}(f)\bigr) .
			\end{equation*}
		\end{remark}
		\begin{remark}
		\label{rem:tilde}
			The condition for $g \sim f$ can be easily seen to be equivalent to $|f-g| \in o(g)$. In Chapter~\ref{chap:problems} we will be mostly interested in this relation because it specifies the function better than $\Theta$. For example, $2n \in \Theta(n)$ but $2n \not\sim n$.
		\end{remark}
	
	\subsection{Languages}
		
		\begin{defn}
			Let $\Sigma$ be a nonempty and finite set of {\em characters} which will be referred to as {\em alphabet}. Define set of {\em words} over alphabet $\Sigma$ as $\Sigma^* = \bigcup_{n\in\N_0}\Sigma^n$ and set of nonempty words as $\Sigma^+ = \bigcup_{n\in\N}\Sigma^n$. Empty word will be denoted by $\epsilon$. {\em Language} ${\cal L}$ over alphabet $\Sigma$ is a set of words: ${\cal L} \subseteq \Sigma^*$. {\em Complement} of language $\cal L$ will be denoted by ${\cal\overline L} = \Sigma^* \setminus {\cal L}$.
		\end{defn}
		
		Let us briefly remind Chomsky hierarchy of languages generated by generative grammars. Denote {\em alphabet of non-terminals} by $N$, {\em alphabet of terminals} by $\Sigma$ and {\em initial symbol} by $I$.
		\begin{description}
			\item[Recursively enumerable (type 0).] Generated by unrestricted grammar rules.
			\item[Context-sensitive (type 1).] Grammar rules are either all of the form $\alpha A \beta \rightarrow \alpha \eta \beta$ where $\alpha,\,\beta\in (N\cup\Sigma)^*$, $A\in N$ and $\eta\in (N\cup\Sigma)^+$. Note that $\eta$ cannot be empty. Or, if we assume these rules without those having $I$ on the right side, then the rule $I\rightarrow \epsilon$ is also allowed.
			\item[Context-free (type 2).] All grammar rules are of the form $A\rightarrow\eta$ where $A\in N$ and $\eta\in (N\cup\Sigma)^*$. Note that $\eta$ can be empty.
			\item[Regular (type 3).] Grammar rules are either all of the form $A\rightarrow bB$ or $A\rightarrow b$ where $A,\,B\in N$ and $b\in\Sigma$. Or, if we assume these rules without those having $I$ on the right side, then the rule $I\rightarrow \epsilon$ is also allowed.
		\end{description}
		
		\begin{remark}
			Note that given an alphabet $\Sigma$ the set of all words $\Sigma^*$ is countable. Moreover, one can sort $\Sigma^*$ first by word length, then lexicographically, thus it is easy to define desired bijection $f: \N \leftrightarrow \Sigma^* $.
			
			Formal language ${\cal L}$ can then be viewed as a boolean function $g: \N \rightarrow \{0,1\}$ defined as
			$g(n) = 1 \iff f(n)\in {\cal L}$.
		\end{remark}
		
		% přidat čim je co rozpoznávatelný?
		% abeceda \Sigma -> {0, 1} ??
	
	\subsection{$\P$, $\NP$ and other classes}
	\label{sec:PNP}
		
		This section describes few classes of languages from the resource-consumption point of view. There exist many equivalent definitions, these are taken from \cite{book_comp}. See also \cite[Chapter 1.5.1]{book_comp} for a discussion reasoning the importance of class $\P$.
		
		\begin{defn}\label{def:P}
			${\cal L} \subseteq \Sigma^*$. ${\cal L} \in \P \iff \bigl(\exists \textnormal{ polynomial } p \bigr) \bigl(\exists \textnormal{ deterministic Turing machine } M\bigr)\\ \bigl(\forall x \in \Sigma^*\bigr) \bigl(x \in {\cal L} \iff M \textnormal{ accepts } x \textnormal{ at most in } p(|x|) \textnormal{ steps} \bigr)$.
		\end{defn}
		\nomenclature{$\cal P$}{Set of polynomials.}
		
		\begin{defn}\label{def:NP}
			${\cal L} \subseteq \Sigma^*$. ${\cal L} \in \NP \iff \bigl(\exists p, q \in {\cal P}\bigr) \bigl(\exists \textnormal{ deterministic Turing machine } M\bigr)\\ \bigl(\forall x \in \Sigma^*\bigr) \Bigl(x \in {\cal L} \iff \bigl(\exists y \in \Sigma^{p(|x|)}\bigr) \bigl(M \textnormal{ accepts } (x,y) \textnormal{ at most in } q(|x|+|y|) \textnormal{ steps} \bigr)\Bigr)$.\\
			Such $y$ will be referred to as {\em certificate} for $x$ (with respect to $\cal L$ and $M$).
		\end{defn}
		
		\begin{defn}\label{def:coNP}
			${\cal L} \subseteq \Sigma^*$. ${\cal L} \in \coNP \iff \bigl(\exists p, q \in {\cal P}\bigr) \bigl(\exists \textnormal{ deterministic Turing machine } M\bigr)\\ \bigl(\forall x \in \Sigma^*\bigr) \Bigl(x \in {\cal L} \iff \bigl(\forall y \in \Sigma^{p(|x|)}\bigr) \bigl(M \textnormal{ accepts } (x,y) \textnormal{ at most in } q(|x|+|y|) \textnormal{ steps} \bigr)\Bigr)$.
		\end{defn}
		
		The second possibility is to first define general classes $\DTime$, $\NTime$, $\DSpace$ and $\NSpace$ and after that to use their special case. Remind how Non-deterministic Turing machine (NTM) differs from Deterministic Turing machine (DTM):
		\begin{itemize}
			\item it is allowed to have ambiguous transition function,
			\item it has two types of terminal states: accepting $q_{accept}$ and halting without accepting nor rejecting $q_{halt}$,
			\item we say that it accepts input $x$ iff there {\em exists} a sequence of decisions ending in $q_{accept}$, as a consequence it declines $x$ iff {\em for every} sequence of decisions it reaches $q_{halt}$.
		\end{itemize}
		
		\begin{defn}\label{def:DTime}
			$\DTime\bigl(f(n)\bigr) = \bigl\{ {\cal L}\textnormal{ language} \bigm| (\exists \textnormal{ deterministic Turing machine }M)\\ (\forall x\in\Sigma^*)\bigl(x\in{\cal L} \iff M\textnormal{ accepts }x\textnormal{ in time }\leq f(|x|)\bigr) \bigr\}$.\\
			Other classes are defined in a very similar manner: time is replaced with space, deterministic is replaced with non-deterministic.
		\end{defn}
		
		\begin{thm}
			\label{thm:P}
			$\P = \bigcup\limits_{k\in\N} \DTime(n^k)$ and $\NP = \bigcup\limits_{k\in\N} \NTime(n^k)$.
		\end{thm}
		
		\begin{thm}
			\label{thm:coNP}
			$ {\cal L} \in \coNP \iff {\cal\overline L} \in \NP $.
		\end{thm}
		
		\begin{note}
			Theorems \ref{thm:P} and \ref{thm:coNP} can be also used as definitions.
		\end{note}
		
		\begin{note}
			$\NP\subseteq\powerset{\Sigma^*}$ where $\powerset{S}$ denotes power set of set $S$, so the notation $\coNP$ might be confusing. Note that $\coNP$ is {\em not} a complement to $\NP$ as a set of languages.
		\end{note}
		
		\begin{remark}
			In case of $\P$ there is no ``co'' version. It follows from ${\cal L} \in \P \iff \overline{\cal L} \in \P$. This can be easily seen because deterministic Turing machine is capable of negation with same time resources greater than $n$, non-deterministic is not known to. Note that Immerman--Szelepcsényi theorem states possibility of non-deterministic Turing machine negation in limited {\em space}: ${\cal L} \in \NSpace(s(n)) \iff \overline{\cal L} \in \NSpace(s(n))$ for $s(n) \geq \log(n)$.
		\end{remark}
		
		\begin{defn}
			We say that language ${\cal L}_1$ is {\em polynomial-time Karp reducible} to ${\cal L}_2 \iff \exists$ polynomial-time computable function $f:\Sigma^*\rightarrow\Sigma^*$ such that $(\forall x\in\Sigma^*)(x\in{\cal L}_1\iff f(x)\in{\cal L}_2)$. This relation is denoted by ${\cal L}_1\propto{\cal L}_2$.
		\end{defn}
		
		\begin{defn}
			${\cal L}\in\NPH \iff (\forall{\cal L'}\in\NP)({\cal L'}\propto{\cal L})$.
		\end{defn}
		
		\begin{defn}
			${\cal L}\in\NPC\iff{\cal L}\in\NP\cap\NPH$.
		\end{defn}
		
		\begin{note}
			If we found a polynomial-time algorithm for {\em any} $\NPC$ language, it would hold $\P=\NP$ which is not believed to be true. Thus assuming that $\P\neq\NP$ there does not exist a deterministic polynomial algorithm for any $\NPC$ language.
		\end{note}
		
		\begin{example}\label{exm:npc}
			Remind some popular $\NPC$ problems: Boolean Formula Satisfiability ($\sf SAT$), Hamiltonian Path Problem ($\sf HPP$), Graph $3$-coloring, Graph $k$-independent Set, Graph $k$-clique, Graph $k$-vertex Cover, Subset Sum and many others.
			
			On the other hand there are few interesting $\NP$ problems which are not known to belong either to $\P$ nor to $\NPC$, one of them is Graph Isomorphism Problem.
		\end{example}
		
		% poly-time hierarchy ... book pg. 93
		
		%!% uvést
		To define probabilistic classes of languages ($\BPP$, $\RP$, $\coRP$ and $\ZPP$) we will remind the concept of Probabilistic Turing machine (PTM). Like NTM it is allowed to have ambiguous transition function, moreover, in every state there is defined a transition probability and it can have another terminal state $q_{reject}$.
		
		Let $M$ be a PTM. We say that $M$
		\begin{itemize}
			\item decides language $\cal L$ iff for every $x\in\Sigma^*$ the probability of halting in correct state (i.e. $q_{accept}$ for $x\in{\cal L}$ and $q_{reject}$ for $x\notin{\cal L}$) is higher than $\nicefrac{2}{3}$,
			\item decides language $\cal L$ in time $t(n)$ iff $M$ decides language $\cal L$ and for every $x\in\Sigma^*$ it halts in time $\leq t(|x|)$ regardless its randomness.
		\end{itemize}
		Now we can define those classes, note that it would be possible to use again two types of definition, like above.
		
		% příp. pg 121 .. tam je alternativní def
		
		\begin{defn}\label{def:BPTime}
			$\BPTime\bigl(f(n)\bigr) = \bigl\{ {\cal L}\textnormal{ language} \bigm| (\exists \textnormal{ probabilistic Turing machine }M)\\ \bigl(M\textnormal{ decides }{\cal L}\textnormal{ in time }\leq f(|x|)\bigr) \bigr\}$.
		\end{defn}
		
		\begin{defn}
			$\BPP = \bigcup\limits_{k\in\N} \BPTime(n^k)$.
		\end{defn}
		
		\begin{defn}
			$\RTime\bigl(f(n)\bigr) = \bigl\{ {\cal L}\textnormal{ language} \bigm| (\exists \textnormal{ probabilistic Turing machine }M)\\ (\forall x\in\Sigma^*)\bigl(M \textnormal{ halts in time } \leq f(|x|) \;\wedge\; x\in{\cal L} \then \prob(M\textnormal{ accepts }x) \geq \nicefrac{2}{3} \;\wedge\\ x\notin{\cal L} \then \prob(M\textnormal{ accepts }x) = 0 \bigr) \bigr\}$.
		\end{defn}
		
		\begin{defn}
			$\RP = \bigcup\limits_{k\in\N} \RTime(n^k)$.
		\end{defn}
		
		\begin{defn}
			$ {\cal L} \in \coRP \iff {\cal\overline L} \in \RP $.
		\end{defn}
		
		\begin{remark}
			$\BPP$ allows PTM to make both wrong decisions (for $x\in\cal L$ as well as for $x\notin\cal L$), on the other hand $\RP$ does not allow error for $x\notin\cal L$ and $\coRP$ does not allow error for $x\in\cal L$. Following class $\ZPP$ (from {\em zero error}) does not allow any error, it only allows halting neither with accepting nor with rejecting.
		\end{remark}
		
		\begin{defn}
			$\ZPTime\bigl(f(n)\bigr) = \Bigl\{ {\cal L}\textnormal{ language} \Bigm| \bigl(\exists \textnormal{ probabilistic Turing machine }M\bigr)\\ \bigl(\forall x\in\Sigma^*\bigr)\Bigl(M \textnormal{ halts in time } \leq f(|x|) \;\wedge\\ \bigl(x\in{\cal L} \then \prob(M\textnormal{ accepts }x) \geq \nicefrac{2}{3} \,\wedge\, \prob(M\textnormal{ rejects }x) = 0 \bigr) \;\wedge\\ \bigl(x\notin{\cal L} \then \prob(M\textnormal{ rejects }x) \geq \nicefrac{2}{3} \,\wedge\, \prob(M\textnormal{ accepts }x) = 0 \bigl) \Bigr) \Bigr\}$.
		\end{defn}
		
		\begin{defn}
			$\ZPP = \bigcup\limits_{k\in\N} \ZPTime(n^k)$.
		\end{defn}
		
		\begin{thm}
			\begin{equation*}
				{\cal L}_{1,2}\in\ZPP \then \{ {\cal\overline L}_1,\,{\cal L}_1\cap{\cal L}_2,\,{\cal L}_1\cup{\cal L}_2\} \subseteq \ZPP .
			\end{equation*}
		\end{thm}
		
		\begin{thm}
			\begin{align*}
				\P \subseteq \ZPP &= \RP \cap \coRP , \\
				\RP &\subseteq \NP\cap\BPP , \\
				\coRP &\subseteq \coNP\cap\BPP .
			\end{align*}
		\end{thm}
		
		\begin{conj}
			\begin{align*}
				\P &\subsetneq \NP, \\
				\P &= \BPP.
			\end{align*}
		\end{conj}
		
		% PP, \#P, PSpace ..? Maybe also polynomial hierarchy: $\Sigma_k P$ and $\Pi_k P$ languages (alternating Turing machine with bounded alternation, \cite{kozen06}). Might be nice to show what DNA computation is capable of.
		
		% SAT: Lipton's contribution using $m$ biosteps ($m = \#clauses$), \cite{lipton95}, Lipton's set of speedup problems, \cite{lipton96speedup}.
		% Energy efficiency (Adleman).